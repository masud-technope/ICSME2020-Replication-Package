{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incredible-nylon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acknowledged-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the data from CSV\n",
    "data = pd.read_csv(\"C:/MyWorks/MyResearch/BugReproduction/ICSME2020-Replication-Package/Machine-Learning-Models/XGBoost/Eclipse-Firefox-1109-Encoded-Dataset-Stale.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "alpha-basis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   component  priority  severity  isDependent  numberOfDepends  doesBlock  \\\n",
      "0          8         3         7            0                0          0   \n",
      "1          8         3         7            0                0          0   \n",
      "2          8         3         6            0                0          0   \n",
      "3          8         3         6            0                0          0   \n",
      "4          8         3         6            0                0          0   \n",
      "\n",
      "   numberOfBlocked  reporterIsAssignee  hasCC  numberOfCC  hasAttachment  \\\n",
      "0                0                   0      1           1              0   \n",
      "1                0                   0      1           2              0   \n",
      "2                0                   0      1           5              0   \n",
      "3                0                   0      1           1              0   \n",
      "4                0                   0      1           2              1   \n",
      "\n",
      "   numberOfAttachment  titleReadability  descReadability  positiveCount  \\\n",
      "0                   0         10.493273        13.314057              0   \n",
      "1                   0         14.690483         7.173732              0   \n",
      "2                   0          5.114435        16.700140              0   \n",
      "3                   0          4.648820        16.813517              0   \n",
      "4                   1         10.557573        19.494838              0   \n",
      "\n",
      "   negativeCount  neutralCount  classlabel  \n",
      "0              0             1           1  \n",
      "1              0             1           1  \n",
      "2              0             1           1  \n",
      "3              0             1           1  \n",
      "4              0             1           1  \n"
     ]
    }
   ],
   "source": [
    "#randomization\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "approximate-first",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component</th>\n",
       "      <th>priority</th>\n",
       "      <th>severity</th>\n",
       "      <th>isDependent</th>\n",
       "      <th>numberOfDepends</th>\n",
       "      <th>doesBlock</th>\n",
       "      <th>numberOfBlocked</th>\n",
       "      <th>reporterIsAssignee</th>\n",
       "      <th>hasCC</th>\n",
       "      <th>numberOfCC</th>\n",
       "      <th>hasAttachment</th>\n",
       "      <th>numberOfAttachment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   component  priority  severity  isDependent  numberOfDepends  doesBlock  \\\n",
       "0         24         5         2            1                0          1   \n",
       "1         24         5         2            1                0          1   \n",
       "2         24         5         3            1                0          1   \n",
       "3         24         5         3            1                0          1   \n",
       "4         24         5         3            1                0          1   \n",
       "\n",
       "   numberOfBlocked  reporterIsAssignee  hasCC  numberOfCC  hasAttachment  \\\n",
       "0                0                   1      2           1              1   \n",
       "1                0                   1      2           2              1   \n",
       "2                0                   1      2           5              1   \n",
       "3                0                   1      2           1              1   \n",
       "4                0                   1      2           2              2   \n",
       "\n",
       "   numberOfAttachment  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#divide the features and classes\n",
    "cols_to_retain = [\"component\",\"priority\",\"severity\",\"isDependent\",\"numberOfDepends\",\"doesBlock\",\"numberOfBlocked\",\n",
    "                  \"reporterIsAssignee\",\"hasCC\",\"numberOfCC\",\"hasAttachment\",\"numberOfAttachment\",\"titleReadability\",\n",
    "                  \"descReadability\",\"positiveCount\",\"negativeCount\",\"neutralCount\"]\n",
    "\n",
    "structurals_only=[\"component\",\"priority\",\"severity\",\"isDependent\",\"numberOfDepends\",\"doesBlock\",\"numberOfBlocked\",\n",
    "                  \"reporterIsAssignee\",\"hasCC\",\"numberOfCC\",\"hasAttachment\",\"numberOfAttachment\"]\n",
    "\n",
    "structurals_readability=[\"component\",\"priority\",\"severity\",\"isDependent\",\"numberOfDepends\",\"doesBlock\",\"numberOfBlocked\",\n",
    "                  \"reporterIsAssignee\",\"hasCC\",\"numberOfCC\",\"hasAttachment\",\"numberOfAttachment\",\"titleReadability\",\n",
    "                  \"descReadability\"]\n",
    "\n",
    "structurals_sentiment=[\"component\",\"priority\",\"severity\",\"isDependent\",\"numberOfDepends\",\"doesBlock\",\"numberOfBlocked\",\n",
    "                  \"reporterIsAssignee\",\"hasCC\",\"numberOfCC\",\"hasAttachment\",\"numberOfAttachment\",\"positiveCount\",\"negativeCount\",\"neutralCount\"]\n",
    "\n",
    "readability_only=[\"titleReadability\",\n",
    "                  \"descReadability\"]\n",
    "\n",
    "sentiment_only=[\"positiveCount\",\"negativeCount\",\"neutralCount\"]\n",
    "\n",
    "X=data[structurals_only]\n",
    "y=data[\"classlabel\"]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "recreational-technician",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the data into K-fold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "spread-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading library for precision, recall, f-score\n",
    "from sklearn.metrics import precision_recall_fscore_support as perf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "blank-secretariat",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\pythonfull\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\programdata\\anaconda3\\envs\\pythonfull\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:09:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.90      0.85        58\n",
      "           2       0.87      0.75      0.81        53\n",
      "\n",
      "    accuracy                           0.83       111\n",
      "   macro avg       0.83      0.83      0.83       111\n",
      "weighted avg       0.83      0.83      0.83       111\n",
      "\n",
      "0.8\n",
      "0.8695652173913043\n",
      "[13:09:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.84      0.84        58\n",
      "           2       0.83      0.81      0.82        53\n",
      "\n",
      "    accuracy                           0.83       111\n",
      "   macro avg       0.83      0.83      0.83       111\n",
      "weighted avg       0.83      0.83      0.83       111\n",
      "\n",
      "0.8305084745762712\n",
      "0.8269230769230769\n",
      "[13:09:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.74      0.77        58\n",
      "           2       0.74      0.79      0.76        53\n",
      "\n",
      "    accuracy                           0.77       111\n",
      "   macro avg       0.77      0.77      0.77       111\n",
      "weighted avg       0.77      0.77      0.77       111\n",
      "\n",
      "0.7962962962962963\n",
      "0.7368421052631579\n",
      "[13:09:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\pythonfull\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\programdata\\anaconda3\\envs\\pythonfull\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.78      0.82        58\n",
      "           2       0.78      0.87      0.82        53\n",
      "\n",
      "    accuracy                           0.82       111\n",
      "   macro avg       0.82      0.82      0.82       111\n",
      "weighted avg       0.82      0.82      0.82       111\n",
      "\n",
      "0.8653846153846154\n",
      "0.7796610169491526\n",
      "[13:09:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.86      0.83        58\n",
      "           2       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.81       111\n",
      "   macro avg       0.81      0.81      0.81       111\n",
      "weighted avg       0.81      0.81      0.81       111\n",
      "\n",
      "0.7936507936507936\n",
      "0.8333333333333334\n",
      "[13:09:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\pythonfull\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\programdata\\anaconda3\\envs\\pythonfull\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.90      0.85        58\n",
      "           2       0.87      0.77      0.82        53\n",
      "\n",
      "    accuracy                           0.84       111\n",
      "   macro avg       0.84      0.84      0.84       111\n",
      "weighted avg       0.84      0.84      0.84       111\n",
      "\n",
      "0.8125\n",
      "0.8723404255319149\n",
      "[13:09:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.75      0.77        57\n",
      "           2       0.75      0.78      0.76        54\n",
      "\n",
      "    accuracy                           0.77       111\n",
      "   macro avg       0.77      0.77      0.77       111\n",
      "weighted avg       0.77      0.77      0.77       111\n",
      "\n",
      "0.7818181818181819\n",
      "0.75\n",
      "[13:09:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\pythonfull\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\programdata\\anaconda3\\envs\\pythonfull\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.79      0.78        57\n",
      "           2       0.77      0.76      0.77        54\n",
      "\n",
      "    accuracy                           0.77       111\n",
      "   macro avg       0.77      0.77      0.77       111\n",
      "weighted avg       0.77      0.77      0.77       111\n",
      "\n",
      "0.7758620689655172\n",
      "0.7735849056603774\n",
      "[13:09:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.84      0.81        57\n",
      "           2       0.82      0.74      0.78        54\n",
      "\n",
      "    accuracy                           0.79       111\n",
      "   macro avg       0.80      0.79      0.79       111\n",
      "weighted avg       0.79      0.79      0.79       111\n",
      "\n",
      "0.7741935483870968\n",
      "0.8163265306122449\n",
      "[13:09:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\pythonfull\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\programdata\\anaconda3\\envs\\pythonfull\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.81      0.79        57\n",
      "           2       0.78      0.75      0.77        53\n",
      "\n",
      "    accuracy                           0.78       110\n",
      "   macro avg       0.78      0.78      0.78       110\n",
      "weighted avg       0.78      0.78      0.78       110\n",
      "\n",
      "0.7796610169491526\n",
      "0.7843137254901961\n"
     ]
    }
   ],
   "source": [
    "#k-fold scores\n",
    "precisions=[]\n",
    "recalls=[]\n",
    "fscores=[]\n",
    "\n",
    "precisions_1=[]\n",
    "recalls_1=[]\n",
    "fscores_1=[]\n",
    "\n",
    "precisions_2=[]\n",
    "recalls_2=[]\n",
    "fscores_2=[]\n",
    "\n",
    "#clr_collection=[]\n",
    "\n",
    "\n",
    "#train and test split using K-fold\n",
    "for train, test in kfold.split(X, y):\n",
    "    #xgb.cv(xgb_params, train, 100, callbacks=[oof_prediction()]), nfold=5)\n",
    "    training_features=X.iloc[train,:]\n",
    "    training_labels=y[train]\n",
    "    test_features=X.iloc[test,:]\n",
    "    test_labels=y[test]\n",
    "    \n",
    "    model = xgb.XGBClassifier(use_label_encoder=True).fit(training_features, training_labels)\n",
    "    predicted_labels = model.predict(test_features)\n",
    "    \n",
    "    #print(test_labels, predicted_labels)\n",
    "    \n",
    "    cm = confusion_matrix(test_labels, predicted_labels)\n",
    "    print(classification_report(test_labels, predicted_labels))\n",
    "    \n",
    "    #print(cm)\n",
    "    #calculating the precision\n",
    "    precision = precision_score(test_labels, predicted_labels, average='weighted')\n",
    "    precision_1 = precision_score(test_labels, predicted_labels, pos_label=1, average=\"binary\")\n",
    "    precision_2 = precision_score(test_labels, predicted_labels, pos_label=2, average=\"binary\")\n",
    "    \n",
    "    print(precision_1)\n",
    "    print(precision_2)\n",
    "    \n",
    "    #calculating the recall\n",
    "    recall=recall_score(test_labels, predicted_labels, average='weighted')\n",
    "    recall_1=recall_score(test_labels, predicted_labels, pos_label=1, average=\"binary\")\n",
    "    recall_2=recall_score(test_labels, predicted_labels, pos_label=2, average=\"binary\")\n",
    "    \n",
    "    \n",
    "    #calculating the f-score\n",
    "    fscore=f1_score(test_labels, predicted_labels, average='weighted')\n",
    "    fscore_1=f1_score(test_labels, predicted_labels, pos_label=1, average=\"binary\")\n",
    "    fscore_2=f1_score(test_labels, predicted_labels, pos_label=2, average=\"binary\")\n",
    "    \n",
    "    \n",
    "    #storing the precision\n",
    "    precisions.append(precision)\n",
    "    precisions_1.append(precision_1)\n",
    "    precisions_2.append(precision_2)\n",
    "    \n",
    "    recalls.append(recall)\n",
    "    recalls_1.append(recall_1)\n",
    "    recalls_2.append(recall_2)\n",
    "    \n",
    "    \n",
    "    fscores.append(fscore)\n",
    "    fscores_1.append(fscore_1)\n",
    "    fscores_2.append(fscore_2)\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "large-sample",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8009874996027925 0.8210223835450696 0.8098371527176338\n",
      "0.8042890337154759 0.7787211740041928 0.7900193872294416\n",
      "0.8025731685004445 0.8007043407043406 0.8003187599300754\n"
     ]
    }
   ],
   "source": [
    "#for class 1\n",
    "print(np.mean(precisions_1), np.mean(recalls_1), np.mean(fscores_1))\n",
    "#print(np.mean(recalls_1))\n",
    "#print(np.mean(fscores_1))\n",
    "\n",
    "#for class 2\n",
    "print(np.mean(precisions_2), np.mean(recalls_2), np.mean(fscores_2))\n",
    "#print(np.mean(recalls_2))\n",
    "#print(np.mean(fscores_2))\n",
    "\n",
    "#printing the results\n",
    "print(np.mean(precisions), np.mean(recalls), np.mean(fscores))\n",
    "#print(np.mean(recalls))\n",
    "#print(np.mean(fscores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-framework",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
